{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture A - Multi Concat Functions with Dropout and using Glover Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Architecture-A---Multi-Concat-Functions-with-Dropout-and-using-Glover-Embedding\" data-toc-modified-id=\"Architecture-A---Multi-Concat-Functions-with-Dropout-and-using-Glover-Embedding-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Architecture A - Multi Concat Functions with Dropout and using Glover Embedding</a></span></li><li><span><a href=\"#Download-libraries-for-Google-Colab-and-Download-Embeddings\" data-toc-modified-id=\"Download-libraries-for-Google-Colab-and-Download-Embeddings-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Download libraries for Google Colab and Download Embeddings</a></span></li><li><span><a href=\"#Import-Data\" data-toc-modified-id=\"Import-Data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Import Data</a></span></li><li><span><a href=\"#Load-Embedding-and-Create-Embedding-Layer\" data-toc-modified-id=\"Load-Embedding-and-Create-Embedding-Layer-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Load Embedding and Create Embedding Layer</a></span></li><li><span><a href=\"#Define-and-Train-Network\" data-toc-modified-id=\"Define-and-Train-Network-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Define and Train Network</a></span></li><li><span><a href=\"#Pass-Train-and-Test-Data-Through-Network-and-Save-for-Stacking\" data-toc-modified-id=\"Pass-Train-and-Test-Data-Through-Network-and-Save-for-Stacking-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Pass Train and Test Data Through Network and Save for Stacking</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7f1fc879ae2f51de5ee911e8119a373b1ba4fbf0",
    "colab_type": "text",
    "id": "x5C57FHH8Rkn"
   },
   "source": [
    "# Download libraries for Google Colab and Download Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T19:25:46.620625Z",
     "start_time": "2018-12-19T19:25:36.583693Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "cZk-JGeTFa_0",
    "outputId": "ca32dc9c-fd39-49dd-e7f9-ab560d3cfc0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==0.23.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/d8/feeb346d41f181e83fba45224ab14a8d8af019b48af742e047f3845d8cff/pandas-0.23.4-cp36-cp36m-manylinux1_x86_64.whl (8.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 8.9MB 4.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.0 in /home/jeroen/miniconda3/lib/python3.6/site-packages (from pandas==0.23.4) (2.7.3)\n",
      "Collecting numpy>=1.9.0 (from pandas==0.23.4)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/7f/9d804d2348471c67a7d8b5f84f9bc59fd1cefa148986f2b74552f8573555/numpy-1.15.4-cp36-cp36m-manylinux1_x86_64.whl (13.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 13.9MB 2.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz>=2011k (from pandas==0.23.4)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/0e/2365ddc010afb3d79147f1dd544e5ee24bf4ece58ab99b16fbb465ce6dc0/pytz-2018.7-py2.py3-none-any.whl (506kB)\n",
      "\u001b[K    100% |████████████████████████████████| 512kB 9.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /home/jeroen/miniconda3/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas==0.23.4) (1.11.0)\n",
      "\u001b[31mtwisted 18.7.0 has requirement Automat>=0.3.0, but you'll have automat 0.0.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, pytz, pandas\n",
      "Successfully installed numpy-1.15.4 pandas-0.23.4 pytz-2018.7\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas==0.23.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qDR834FhFoYI",
    "outputId": "f887224a-90fa-48c1-a5aa-702004b8ae7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.22.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "bSjcF-ie9vqH",
    "outputId": "202bc313-68b8-4265-e484-b9c2c5bebdba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-12-12 20:04:00--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2018-12-12 20:04:00--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  86.0MB/s    in 9.2s    \n",
      "\n",
      "2018-12-12 20:04:09 (89.6 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "EKVjdxnm-5jV",
    "outputId": "9470cfd5-246a-480e-9b0f-38c2e44f33e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  glove.6B.zip\n",
      "  inflating: glove.6B.50d.txt        \n",
      "  inflating: glove.6B.100d.txt       \n",
      "  inflating: glove.6B.200d.txt       \n",
      "  inflating: glove.6B.300d.txt       \n"
     ]
    }
   ],
   "source": [
    "! unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cAxe2i-G-_aI"
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:22:06.696094Z",
     "start_time": "2018-12-03T07:22:06.268835Z"
    },
    "_uuid": "cbd07f9d34f86a58595067c6f1dccb39850527cc",
    "colab": {},
    "colab_type": "code",
    "id": "u9oY0ixH8Rkq",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hwyhbYREgkRe",
    "outputId": "3fb3173e-cb8e-443a-bad4-a3aa1ec1fa1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.4'"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v5FdaALfgvYk"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train_data.csv\",doublequote=True,quotechar='\"',sep=\",\").drop(\"is_duplicate\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:22:07.748093Z",
     "start_time": "2018-12-03T07:22:07.630284Z"
    },
    "_uuid": "22768bf18f84f81d6de2cccc0853ee03c4985772",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "CEtdLpDn8RlE",
    "outputId": "1e771f55-5180-477f-ac52-388eaae43798"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  is_duplicate\n",
       "0   0             0\n",
       "1   1             0\n",
       "2   2             0\n",
       "3   3             0\n",
       "4   4             0"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t_labels= pd.read_csv('train_labels.csv', encoding='utf-8')\n",
    "df_t_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:22:08.109493Z",
     "start_time": "2018-12-03T07:22:07.751733Z"
    },
    "_uuid": "082e1aa70a2c860a81ffa5d0820407aff9a285f4",
    "colab": {},
    "colab_type": "code",
    "id": "wFoa62bD8RlI"
   },
   "outputs": [],
   "source": [
    "df_train = df_train.merge(df_t_labels,on=[\"id\"],how=\"inner\")\n",
    "df_train.head()\n",
    "df_train['id'] = df_train['id'].apply(str)\n",
    "df_train['is_duplicate'] = df_train['is_duplicate'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:22:08.281182Z",
     "start_time": "2018-12-03T07:22:08.140777Z"
    },
    "_uuid": "5b646581d786a7e45d5e7f0cedcfd9fafeac3552",
    "colab": {},
    "colab_type": "code",
    "id": "BPoyvIb_8RlR"
   },
   "outputs": [],
   "source": [
    "df_train['question1'].fillna('', inplace=True)\n",
    "df_train['question2'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dNIJKeiAF5hf",
    "outputId": "14ad2191-e0a8-481b-af0b-031bfa10bd3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.4'"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:22:08.522485Z",
     "start_time": "2018-12-03T07:22:08.283282Z"
    },
    "_uuid": "82c5dfe1ed458b7bbf336b3be0485c5faf588dd5",
    "colab": {},
    "colab_type": "code",
    "id": "GBj-sEeG8RlU"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_data.csv',doublequote=True)\n",
    "df_test['test_id'] = df_test['test_id'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:22:08.911150Z",
     "start_time": "2018-12-03T07:22:08.524588Z"
    },
    "_uuid": "e6e75ae38bcae9d418a3616bf712d1c457afad43",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "nOpryMQc8RlX",
    "outputId": "750094b4-4ebd-4ef4-e50f-ed4a5f0df110"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.concat((df_train, df_test))\n",
    "df_all['question1'].fillna('', inplace=True)\n",
    "df_all['question2'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:22:09.298149Z",
     "start_time": "2018-12-03T07:22:08.930018Z"
    },
    "_uuid": "3c844458d3b15d6e9692cabc783d568a793b0000",
    "colab": {},
    "colab_type": "code",
    "id": "Gto3hCeC8Rlh"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:22:21.640288Z",
     "start_time": "2018-12-03T07:22:09.300685Z"
    },
    "_uuid": "1441257c592632854f5bb2eefefe62e2ffeeb8b4",
    "colab": {},
    "colab_type": "code",
    "id": "YPYeAHEw8Rlk"
   },
   "outputs": [],
   "source": [
    "counts_vectorizer = CountVectorizer(max_features=10000-1).fit(\n",
    "    itertools.chain(df_all['question1'], df_all['question2']))\n",
    "\n",
    "other_index = len(counts_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:22:23.303725Z",
     "start_time": "2018-12-03T07:22:21.641852Z"
    },
    "_uuid": "eef9b41700c8545288afb21acc249a61ba36deac",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "LHHo2dRN8Rlo",
    "outputId": "459d8936-00ed-496a-ceb8-54bbadf6944d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras \n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:22:23.309534Z",
     "start_time": "2018-12-03T07:22:23.305897Z"
    },
    "_uuid": "1b0456d3899305fa68a305c44ac143b38a324d1c",
    "colab": {},
    "colab_type": "code",
    "id": "B8-xp-i_8Rlr"
   },
   "outputs": [],
   "source": [
    "words_tokenizer = re.compile(counts_vectorizer.token_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:22:23.322370Z",
     "start_time": "2018-12-03T07:22:23.312029Z"
    },
    "_uuid": "eba36585ada62745fd9494559ec265e45344a8e3",
    "colab": {},
    "colab_type": "code",
    "id": "htDh1abY8Rlx"
   },
   "outputs": [],
   "source": [
    "def create_padded_seqs(texts, max_len=30):\n",
    "    seqs = texts.apply(lambda s: \n",
    "        [counts_vectorizer.vocabulary_[w] if w in counts_vectorizer.vocabulary_ else other_index\n",
    "         for w in words_tokenizer.findall(s.lower())])\n",
    "    return pad_sequences(seqs, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WwbjDiODTxBp"
   },
   "outputs": [],
   "source": [
    "nlp_train_df = pd.read_csv(\"train_features_31.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "fXfP2oP7fRCu",
    "outputId": "3dda6021-ec8e-40d8-ea60-30d44eba6a9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(323164, 31)\n",
      "(323164, 32)\n"
     ]
    }
   ],
   "source": [
    "print(nlp_train_df.drop(\"id\",axis=1).shape)\n",
    "print(nlp_train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:22:35.799021Z",
     "start_time": "2018-12-03T07:22:23.324561Z"
    },
    "_uuid": "b130f6a4dadcf25e245e63a2e99cb06b5356d74d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "gZOZtXRl8Rl6",
    "outputId": "95ee1bf4-530e-454e-b6d3-8615d06dd78d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "X1_train, X1_val, X2_train, X2_val, y_train, y_val, train_id, train_val_id, nlp_train, nlp_val= \\\n",
    "    train_test_split(create_padded_seqs(df_train['question1']),\n",
    "                     create_padded_seqs(df_train['question2']),\n",
    "                     df_train['is_duplicate'].values,\n",
    "                     df_train.id,\n",
    "                     nlp_train_df.drop(\"id\",axis=1).as_matrix(),\n",
    "                     stratify=df_train['is_duplicate'].values,\n",
    "                     test_size=0.3, random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZL2vq_gXawE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g4a0X0CZMBYX"
   },
   "outputs": [],
   "source": [
    "train_id_pd = pd.DataFrame(train_id.values)\n",
    "train_val_id_pd = pd.DataFrame(train_val_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O9Nuk3zDN1oF"
   },
   "outputs": [],
   "source": [
    "train_id_pd.to_csv(\"train_id_multiple_merge_dropout.csv\",index=False)\n",
    "train_val_id_pd.to_csv(\"train_val_id_multiple_merge_dropout.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "baa0cdb1a6f3d43d9c10d8994ac323ca8675304d",
    "colab_type": "text",
    "id": "3gGVTptx8Rl_"
   },
   "source": [
    "# Load Embedding and Create Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:23:12.888232Z",
     "start_time": "2018-12-03T07:22:35.800623Z"
    },
    "_uuid": "d776d24783e3b723eb6c49a660ccba00891c0c2b",
    "colab": {},
    "colab_type": "code",
    "id": "DqmZ_sWh8RmA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "GLOVE_DIR = \"\"\n",
    "\n",
    "embeddings_index = {}\n",
    "line_num = 0\n",
    "\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.300d.txt'))\n",
    "ff = list(f)\n",
    "f.close()\n",
    "\n",
    "for line in ff:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "    line_num += 1\n",
    "    if line_num == 400000:\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:23:12.939567Z",
     "start_time": "2018-12-03T07:23:12.890096Z"
    },
    "_uuid": "6bd2dc8d80c5d1625b52e25bb7e3d9159e2d02fa",
    "colab": {},
    "colab_type": "code",
    "id": "17E4B_WC8RmI"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "\n",
    "word_index = counts_vectorizer.vocabulary_\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:23:12.968662Z",
     "start_time": "2018-12-03T07:23:12.946336Z"
    },
    "_uuid": "dd550fd808132fc4454ce689155dfe6ca6b27b6c",
    "colab": {},
    "colab_type": "code",
    "id": "D6bJONe18RmM"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = X1_train.shape[1]\n",
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a0744cffaf5770637c89c8f3649b48e625470ef0",
    "colab_type": "text",
    "id": "yRbk0yJQ8RmQ"
   },
   "source": [
    "# Define and Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "996a9458e8adaf6f9da175d2ad46d0a856a60172",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tQwhw1T08RmR",
    "outputId": "35397150-dcc1-4c44-897d-0d5eebd9ebb6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:23:12.973807Z",
     "start_time": "2018-12-03T07:23:12.971013Z"
    },
    "_uuid": "3e30e0fa371ddafe97293abbd88d617d8fc39b1b",
    "colab": {},
    "colab_type": "code",
    "id": "-koH4sSU8RmV"
   },
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "colab_type": "code",
    "id": "wmFFxAo2vWNx",
    "outputId": "4c100206-b884-4790-ea5b-7d6e940bc6a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 30, 300)      3000000     input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 256)          570368      embedding_1[4][0]                \n",
      "                                                                 embedding_1[5][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 256)          0           lstm_3[0][0]                     \n",
      "                                                                 lstm_3[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "subtract_3 (Subtract)           (None, 256)          0           lstm_3[0][0]                     \n",
      "                                                                 lstm_3[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 256)          0           lstm_3[0][0]                     \n",
      "                                                                 lstm_3[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "maximum_3 (Maximum)             (None, 256)          0           lstm_3[0][0]                     \n",
      "                                                                 lstm_3[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1024)         0           multiply_3[0][0]                 \n",
      "                                                                 subtract_3[0][0]                 \n",
      "                                                                 add_3[0][0]                      \n",
      "                                                                 maximum_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1024)         0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 100)          102500      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 100)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 100)          10100       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            101         dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,683,069\n",
      "Trainable params: 683,069\n",
      "Non-trainable params: 3,000,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "words_embedding_layer = embedding_layer\n",
    "seq_embedding_layer = LSTM(256, activation='tanh')\n",
    "\n",
    "input1_tensor = Input(X1_train.shape[1:])\n",
    "input2_tensor = Input(X2_train.shape[1:])\n",
    "\n",
    "words_embedding_layer1 = words_embedding_layer(input1_tensor)\n",
    "words_embedding_layer2 = words_embedding_layer(input2_tensor)\n",
    "\n",
    "seq_embedding_layer1 = seq_embedding_layer(words_embedding_layer1) \n",
    "seq_embedding_layer2 = seq_embedding_layer(words_embedding_layer2)\n",
    "\n",
    "multiply_merge = multiply([seq_embedding_layer1, seq_embedding_layer2])\n",
    "\n",
    "sub_merge = subtract([seq_embedding_layer1, seq_embedding_layer2])\n",
    "\n",
    "add_merge = add([seq_embedding_layer1, seq_embedding_layer2])\n",
    "\n",
    "max_merge = maximum([seq_embedding_layer1, seq_embedding_layer2])\n",
    "\n",
    "merge_layer = concatenate([multiply_merge, sub_merge, add_merge,max_merge])\n",
    "\n",
    "dropout1 = Dropout(0.15)(merge_layer)\n",
    "\n",
    "dense1_layer = Dense(100, activation='sigmoid')(dropout1)\n",
    "\n",
    "dropout2 = Dropout(0.15)(dense1_layer)\n",
    "\n",
    "dense2_layer = Dense(100, activation='sigmoid')(dropout2)\n",
    "\n",
    "\n",
    "ouput_layer = Dense(1, activation='sigmoid')(dense2_layer)\n",
    "\n",
    "model = Model([input1_tensor, input2_tensor], ouput_layer)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QhoUwlrQ4ldv"
   },
   "outputs": [],
   "source": [
    "# with 300d\n",
    "#Epoch 00003: val_loss improved from 0.42090 to 0.39988, saving model to weights.best.Siamese.gloverLSTM256\n",
    "#Epoch 4/5\n",
    "#226214/226214 [==============================] - 329s 1ms/step - loss: 0.3274 - acc: 0.8537 - val_loss: 0.3956 - val_acc: 0.8191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Z0qv4cAgPhAT",
    "outputId": "60336da7-687a-41a8-f6fd-c41f1153edac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘weights.LSTM256.multiple.merge’: File exists\n"
     ]
    }
   ],
   "source": [
    "! mkdir weights.LSTM256.multiple.merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "bbc5078a16a2fabc4601d25e90c205af8edacb5e",
    "colab": {},
    "colab_type": "code",
    "id": "EzlbYMKw8Rmn"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "\n",
    "directory = \"weights.LSTM256.multiple.merge/dropout.{epoch:02d}-{loss:.2f}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=directory, \n",
    "                               verbose=1, save_best_only=False,monitor=\"val_loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "gpfRoPtR3cWm",
    "outputId": "6c9a04eb-9bbc-40bb-d66c-643d66884030"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 226214 samples, validate on 96950 samples\n",
      "Epoch 1/5\n",
      "226214/226214 [==============================] - 314s 1ms/step - loss: 0.4712 - acc: 0.7670 - val_loss: 0.4171 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00001: saving model to weights.LSTM256.multiple.merge/dropout.01-0.47-0.42.hdf5\n",
      "Epoch 2/5\n",
      "226214/226214 [==============================] - 511s 2ms/step - loss: 0.3835 - acc: 0.8205 - val_loss: 0.3876 - val_acc: 0.8181\n",
      "\n",
      "Epoch 00002: saving model to weights.LSTM256.multiple.merge/dropout.02-0.38-0.39.hdf5\n",
      "Epoch 3/5\n",
      "226214/226214 [==============================] - 871s 4ms/step - loss: 0.3354 - acc: 0.8477 - val_loss: 0.3732 - val_acc: 0.8273\n",
      "\n",
      "Epoch 00003: saving model to weights.LSTM256.multiple.merge/dropout.03-0.34-0.37.hdf5\n",
      "Epoch 4/5\n",
      "226214/226214 [==============================] - 883s 4ms/step - loss: 0.2912 - acc: 0.8707 - val_loss: 0.3755 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00004: saving model to weights.LSTM256.multiple.merge/dropout.04-0.29-0.38.hdf5\n",
      "Epoch 5/5\n",
      "226214/226214 [==============================] - 887s 4ms/step - loss: 0.2490 - acc: 0.8916 - val_loss: 0.3866 - val_acc: 0.8340\n",
      "\n",
      "Epoch 00005: saving model to weights.LSTM256.multiple.merge/dropout.05-0.25-0.39.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f35ece05b00>"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X1_train, X2_train], \n",
    "          y_train, \n",
    "            batch_size=128, \n",
    "            epochs=5,\n",
    "            callbacks=[checkpointer],\n",
    "            validation_data=([X1_val, X2_val], y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EBeMwQ2G3cS9"
   },
   "outputs": [],
   "source": [
    "#gloverd100\n",
    "#dropout\n",
    "#multi-merge\n",
    "\n",
    "#Train on 226214 samples, validate on 96950 samples\n",
    "#Epoch 1/5\n",
    "#226214/226214 [==============================] - 314s 1ms/step - loss: 0.4712 - acc: 0.7670 - val_loss: 0.4171 - val_acc: 0.8005\n",
    "#\n",
    "#Epoch 00001: saving model to weights.LSTM256.multiple.merge/dropout.01-0.47-0.42.hdf5\n",
    "#Epoch 2/5\n",
    "#226214/226214 [==============================] - 511s 2ms/step - loss: 0.3835 - acc: 0.8205 - val_loss: 0.3876 - val_acc: 0.8181\n",
    "#\n",
    "#Epoch 00002: saving model to weights.LSTM256.multiple.merge/dropout.02-0.38-0.39.hdf5\n",
    "#Epoch 3/5\n",
    "#226214/226214 [==============================] - 871s 4ms/step - loss: 0.3354 - acc: 0.8477 - val_loss: 0.3732 - val_acc: 0.8273\n",
    "#\n",
    "#Epoch 00003: saving model to weights.LSTM256.multiple.merge/dropout.03-0.34-0.37.hdf5\n",
    "#Epoch 4/5\n",
    "#226214/226214 [==============================] - 883s 4ms/step - loss: 0.2912 - acc: 0.8707 - val_loss: 0.3755 - val_acc: 0.8323\n",
    "#\n",
    "#Epoch 00004: saving model to weights.LSTM256.multiple.merge/dropout.04-0.29-0.38.hdf5\n",
    "#Epoch 5/5\n",
    "#226214/226214 [==============================] - 887s 4ms/step - loss: 0.2490 - acc: 0.8916 - val_loss: 0.3866 - val_acc: 0.8340\n",
    "#\n",
    "#Epoch 00005: saving model to weights.LSTM256.multiple.merge/dropout.05-0.25-0.39.hdf5\n",
    "#<keras.callbacks.History at 0x7f35ece05b00>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6IBEWMmF3cMu"
   },
   "outputs": [],
   "source": [
    "# Load Best Epoch\n",
    "model.load_weights(\"weights.LSTM256.multiple.merge/dropout.02-0.38-0.39.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J_JyLaqxTJ62"
   },
   "source": [
    "# Pass Train and Test Data Through Network and Save for Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F4rjd3K9T2s3"
   },
   "outputs": [],
   "source": [
    "features_model_16 = Model([input1_tensor, input2_tensor], dense1_layer)\n",
    "features_model_16.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zj1cDtIQixvu"
   },
   "outputs": [],
   "source": [
    "train_preds = [create_padded_seqs(df_train['question1']),create_padded_seqs(df_train['question2'])]\n",
    "test_preds = [create_padded_seqs(df_test['question1']),create_padded_seqs(df_test['question2'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qjizSpq6T2V_"
   },
   "outputs": [],
   "source": [
    "F_train_16 = features_model_16.predict(train_preds, batch_size=128)\n",
    "F_test_16 = features_model_16.predict(test_preds, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hbMiNLdYjVZ_"
   },
   "outputs": [],
   "source": [
    "F_train_1 = model.predict(train_preds, batch_size=128)\n",
    "F_test_1 = model.predict(test_preds, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ieHj5UAb1zJz"
   },
   "outputs": [],
   "source": [
    "test_1 = pd.concat([df_test.test_id,pd.DataFrame(F_test_1)],axis=1)\n",
    "test_16 = pd.concat([df_test.test_id,pd.DataFrame(F_test_16)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "Yq_UWyDh2aoA",
    "outputId": "8ef0be29-f47f-4d11-d6b1-7a18376af60d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81126, 2)\n",
      "(81126, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>...</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>0.800644</td>\n",
       "      <td>0.011924</td>\n",
       "      <td>0.887471</td>\n",
       "      <td>0.821151</td>\n",
       "      <td>0.005397</td>\n",
       "      <td>0.052657</td>\n",
       "      <td>0.909325</td>\n",
       "      <td>0.003853</td>\n",
       "      <td>0.027626</td>\n",
       "      <td>0.909195</td>\n",
       "      <td>0.015163</td>\n",
       "      <td>0.797268</td>\n",
       "      <td>0.946934</td>\n",
       "      <td>0.010175</td>\n",
       "      <td>0.847477</td>\n",
       "      <td>0.793004</td>\n",
       "      <td>0.014024</td>\n",
       "      <td>0.017926</td>\n",
       "      <td>0.011315</td>\n",
       "      <td>0.013858</td>\n",
       "      <td>0.012912</td>\n",
       "      <td>0.05535</td>\n",
       "      <td>0.669011</td>\n",
       "      <td>0.016277</td>\n",
       "      <td>0.057484</td>\n",
       "      <td>0.009332</td>\n",
       "      <td>0.042779</td>\n",
       "      <td>0.010491</td>\n",
       "      <td>0.016269</td>\n",
       "      <td>0.018689</td>\n",
       "      <td>0.552569</td>\n",
       "      <td>0.830185</td>\n",
       "      <td>0.008974</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.923107</td>\n",
       "      <td>0.862485</td>\n",
       "      <td>0.751753</td>\n",
       "      <td>0.015057</td>\n",
       "      <td>0.903913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056969</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.558022</td>\n",
       "      <td>0.702742</td>\n",
       "      <td>0.914065</td>\n",
       "      <td>0.778544</td>\n",
       "      <td>0.027683</td>\n",
       "      <td>0.017505</td>\n",
       "      <td>0.072732</td>\n",
       "      <td>0.767495</td>\n",
       "      <td>0.851849</td>\n",
       "      <td>0.028745</td>\n",
       "      <td>0.955579</td>\n",
       "      <td>0.009185</td>\n",
       "      <td>0.012054</td>\n",
       "      <td>0.842147</td>\n",
       "      <td>0.763231</td>\n",
       "      <td>0.020196</td>\n",
       "      <td>0.040096</td>\n",
       "      <td>0.017247</td>\n",
       "      <td>0.683329</td>\n",
       "      <td>0.036683</td>\n",
       "      <td>0.845951</td>\n",
       "      <td>0.009065</td>\n",
       "      <td>0.008742</td>\n",
       "      <td>0.061022</td>\n",
       "      <td>0.012774</td>\n",
       "      <td>0.040569</td>\n",
       "      <td>0.018408</td>\n",
       "      <td>0.726537</td>\n",
       "      <td>0.029499</td>\n",
       "      <td>0.010284</td>\n",
       "      <td>0.711195</td>\n",
       "      <td>0.576707</td>\n",
       "      <td>0.929686</td>\n",
       "      <td>0.539161</td>\n",
       "      <td>0.804008</td>\n",
       "      <td>0.848154</td>\n",
       "      <td>0.033959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  test_id         0         1    ...           97        98        99\n",
       "0      15  0.800644  0.011924    ...     0.804008  0.848154  0.033959\n",
       "\n",
       "[1 rows x 101 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_1.shape)\n",
    "print(df_test.shape)\n",
    "test_16.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-IPCS8f42HOH"
   },
   "outputs": [],
   "source": [
    "train_1 = pd.concat([df_train.id,pd.DataFrame(F_train_1)],axis=1)\n",
    "train_16 = pd.concat([df_train.id,pd.DataFrame(F_train_16)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "QHwBQUvl2zgu",
    "outputId": "455ea0f9-76fd-43a6-b8a6-d9a34886c729"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(323164, 2)\n",
      "(323164, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>...</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0529</td>\n",
       "      <td>0.025055</td>\n",
       "      <td>0.318428</td>\n",
       "      <td>0.50657</td>\n",
       "      <td>0.020913</td>\n",
       "      <td>0.023034</td>\n",
       "      <td>0.675262</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>0.018225</td>\n",
       "      <td>0.629039</td>\n",
       "      <td>0.013483</td>\n",
       "      <td>0.603198</td>\n",
       "      <td>0.006767</td>\n",
       "      <td>0.016828</td>\n",
       "      <td>0.302478</td>\n",
       "      <td>0.741219</td>\n",
       "      <td>0.049589</td>\n",
       "      <td>0.087637</td>\n",
       "      <td>0.137847</td>\n",
       "      <td>0.033844</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.180749</td>\n",
       "      <td>0.153638</td>\n",
       "      <td>0.02582</td>\n",
       "      <td>0.140611</td>\n",
       "      <td>0.057422</td>\n",
       "      <td>0.082687</td>\n",
       "      <td>0.036608</td>\n",
       "      <td>0.033327</td>\n",
       "      <td>0.048423</td>\n",
       "      <td>0.080166</td>\n",
       "      <td>0.185999</td>\n",
       "      <td>0.012485</td>\n",
       "      <td>0.015729</td>\n",
       "      <td>0.284244</td>\n",
       "      <td>0.637421</td>\n",
       "      <td>0.463412</td>\n",
       "      <td>0.023377</td>\n",
       "      <td>0.364163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127946</td>\n",
       "      <td>0.038022</td>\n",
       "      <td>0.024877</td>\n",
       "      <td>0.489653</td>\n",
       "      <td>0.1676</td>\n",
       "      <td>0.734839</td>\n",
       "      <td>0.329826</td>\n",
       "      <td>0.125758</td>\n",
       "      <td>0.042801</td>\n",
       "      <td>0.109782</td>\n",
       "      <td>0.357218</td>\n",
       "      <td>0.330495</td>\n",
       "      <td>0.045412</td>\n",
       "      <td>0.155905</td>\n",
       "      <td>0.021132</td>\n",
       "      <td>0.024861</td>\n",
       "      <td>0.357092</td>\n",
       "      <td>0.149614</td>\n",
       "      <td>0.030009</td>\n",
       "      <td>0.04164</td>\n",
       "      <td>0.02448</td>\n",
       "      <td>0.13045</td>\n",
       "      <td>0.020895</td>\n",
       "      <td>0.410603</td>\n",
       "      <td>0.020111</td>\n",
       "      <td>0.01846</td>\n",
       "      <td>0.197218</td>\n",
       "      <td>0.046063</td>\n",
       "      <td>0.054779</td>\n",
       "      <td>0.018068</td>\n",
       "      <td>0.337488</td>\n",
       "      <td>0.059948</td>\n",
       "      <td>0.07311</td>\n",
       "      <td>0.445842</td>\n",
       "      <td>0.241049</td>\n",
       "      <td>0.592366</td>\n",
       "      <td>0.009818</td>\n",
       "      <td>0.539237</td>\n",
       "      <td>0.533372</td>\n",
       "      <td>0.063803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id       0         1    ...           97        98        99\n",
       "0  0  0.0529  0.025055    ...     0.539237  0.533372  0.063803\n",
       "\n",
       "[1 rows x 101 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_1.shape)\n",
    "print(df_train.shape)\n",
    "train_16.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tmo1rBgB34z5"
   },
   "outputs": [],
   "source": [
    "train_16.to_csv(\"train_16_multi_merge_dropout.csv\",index=False)\n",
    "train_1.to_csv(\"train_1_merge_dropout.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "oHVbD1-sPgqp",
    "outputId": "d0d3a3c9-8672-4b66-d768-fc35a76faf24"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>...</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.052900</td>\n",
       "      <td>0.025055</td>\n",
       "      <td>0.318428</td>\n",
       "      <td>0.506570</td>\n",
       "      <td>0.020913</td>\n",
       "      <td>0.023034</td>\n",
       "      <td>0.675262</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>0.018225</td>\n",
       "      <td>0.629039</td>\n",
       "      <td>0.013483</td>\n",
       "      <td>0.603198</td>\n",
       "      <td>0.006767</td>\n",
       "      <td>0.016828</td>\n",
       "      <td>0.302478</td>\n",
       "      <td>0.741219</td>\n",
       "      <td>0.049589</td>\n",
       "      <td>0.087637</td>\n",
       "      <td>0.137847</td>\n",
       "      <td>0.033844</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.180749</td>\n",
       "      <td>0.153638</td>\n",
       "      <td>0.025820</td>\n",
       "      <td>0.140611</td>\n",
       "      <td>0.057422</td>\n",
       "      <td>0.082687</td>\n",
       "      <td>0.036608</td>\n",
       "      <td>0.033327</td>\n",
       "      <td>0.048423</td>\n",
       "      <td>0.080166</td>\n",
       "      <td>0.185999</td>\n",
       "      <td>0.012485</td>\n",
       "      <td>0.015729</td>\n",
       "      <td>0.284244</td>\n",
       "      <td>0.637421</td>\n",
       "      <td>0.463412</td>\n",
       "      <td>0.023377</td>\n",
       "      <td>0.364163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127946</td>\n",
       "      <td>0.038022</td>\n",
       "      <td>0.024877</td>\n",
       "      <td>0.489653</td>\n",
       "      <td>0.167600</td>\n",
       "      <td>0.734840</td>\n",
       "      <td>0.329826</td>\n",
       "      <td>0.125758</td>\n",
       "      <td>0.042801</td>\n",
       "      <td>0.109782</td>\n",
       "      <td>0.357218</td>\n",
       "      <td>0.330495</td>\n",
       "      <td>0.045412</td>\n",
       "      <td>0.155905</td>\n",
       "      <td>0.021132</td>\n",
       "      <td>0.024861</td>\n",
       "      <td>0.357092</td>\n",
       "      <td>0.149614</td>\n",
       "      <td>0.030009</td>\n",
       "      <td>0.041640</td>\n",
       "      <td>0.024480</td>\n",
       "      <td>0.130450</td>\n",
       "      <td>0.020895</td>\n",
       "      <td>0.410603</td>\n",
       "      <td>0.020111</td>\n",
       "      <td>0.018460</td>\n",
       "      <td>0.197218</td>\n",
       "      <td>0.046063</td>\n",
       "      <td>0.054779</td>\n",
       "      <td>0.018068</td>\n",
       "      <td>0.337488</td>\n",
       "      <td>0.059948</td>\n",
       "      <td>0.073110</td>\n",
       "      <td>0.445842</td>\n",
       "      <td>0.241049</td>\n",
       "      <td>0.592366</td>\n",
       "      <td>0.009818</td>\n",
       "      <td>0.539237</td>\n",
       "      <td>0.533372</td>\n",
       "      <td>0.063803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.013695</td>\n",
       "      <td>0.145779</td>\n",
       "      <td>0.079324</td>\n",
       "      <td>0.071615</td>\n",
       "      <td>0.215110</td>\n",
       "      <td>0.241945</td>\n",
       "      <td>0.076339</td>\n",
       "      <td>0.193873</td>\n",
       "      <td>0.115941</td>\n",
       "      <td>0.122648</td>\n",
       "      <td>0.294601</td>\n",
       "      <td>0.106935</td>\n",
       "      <td>0.002617</td>\n",
       "      <td>0.327100</td>\n",
       "      <td>0.090014</td>\n",
       "      <td>0.017598</td>\n",
       "      <td>0.278505</td>\n",
       "      <td>0.621992</td>\n",
       "      <td>0.211655</td>\n",
       "      <td>0.583829</td>\n",
       "      <td>0.383984</td>\n",
       "      <td>0.283039</td>\n",
       "      <td>0.029181</td>\n",
       "      <td>0.464668</td>\n",
       "      <td>0.754974</td>\n",
       "      <td>0.344025</td>\n",
       "      <td>0.454034</td>\n",
       "      <td>0.218219</td>\n",
       "      <td>0.419860</td>\n",
       "      <td>0.282790</td>\n",
       "      <td>0.018985</td>\n",
       "      <td>0.028972</td>\n",
       "      <td>0.214981</td>\n",
       "      <td>0.293527</td>\n",
       "      <td>0.018983</td>\n",
       "      <td>0.053465</td>\n",
       "      <td>0.030082</td>\n",
       "      <td>0.469298</td>\n",
       "      <td>0.071777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575017</td>\n",
       "      <td>0.293818</td>\n",
       "      <td>0.198420</td>\n",
       "      <td>0.012704</td>\n",
       "      <td>0.030329</td>\n",
       "      <td>0.018374</td>\n",
       "      <td>0.012731</td>\n",
       "      <td>0.812980</td>\n",
       "      <td>0.449378</td>\n",
       "      <td>0.576248</td>\n",
       "      <td>0.050341</td>\n",
       "      <td>0.030157</td>\n",
       "      <td>0.225895</td>\n",
       "      <td>0.216638</td>\n",
       "      <td>0.387833</td>\n",
       "      <td>0.545361</td>\n",
       "      <td>0.091207</td>\n",
       "      <td>0.025223</td>\n",
       "      <td>0.675127</td>\n",
       "      <td>0.164489</td>\n",
       "      <td>0.172073</td>\n",
       "      <td>0.011124</td>\n",
       "      <td>0.625859</td>\n",
       "      <td>0.051404</td>\n",
       "      <td>0.377757</td>\n",
       "      <td>0.262307</td>\n",
       "      <td>0.452393</td>\n",
       "      <td>0.235349</td>\n",
       "      <td>0.328871</td>\n",
       "      <td>0.248712</td>\n",
       "      <td>0.021916</td>\n",
       "      <td>0.590705</td>\n",
       "      <td>0.753402</td>\n",
       "      <td>0.025976</td>\n",
       "      <td>0.022266</td>\n",
       "      <td>0.193322</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.069366</td>\n",
       "      <td>0.059980</td>\n",
       "      <td>0.576983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.072572</td>\n",
       "      <td>0.104996</td>\n",
       "      <td>0.354583</td>\n",
       "      <td>0.491617</td>\n",
       "      <td>0.076595</td>\n",
       "      <td>0.110560</td>\n",
       "      <td>0.140739</td>\n",
       "      <td>0.132093</td>\n",
       "      <td>0.139132</td>\n",
       "      <td>0.272483</td>\n",
       "      <td>0.260845</td>\n",
       "      <td>0.355731</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.419366</td>\n",
       "      <td>0.217963</td>\n",
       "      <td>0.244305</td>\n",
       "      <td>0.191362</td>\n",
       "      <td>0.202435</td>\n",
       "      <td>0.248744</td>\n",
       "      <td>0.217868</td>\n",
       "      <td>0.370406</td>\n",
       "      <td>0.211159</td>\n",
       "      <td>0.029961</td>\n",
       "      <td>0.271763</td>\n",
       "      <td>0.636783</td>\n",
       "      <td>0.130924</td>\n",
       "      <td>0.286630</td>\n",
       "      <td>0.190934</td>\n",
       "      <td>0.068344</td>\n",
       "      <td>0.767804</td>\n",
       "      <td>0.123639</td>\n",
       "      <td>0.109012</td>\n",
       "      <td>0.116066</td>\n",
       "      <td>0.224112</td>\n",
       "      <td>0.047043</td>\n",
       "      <td>0.171371</td>\n",
       "      <td>0.274246</td>\n",
       "      <td>0.117537</td>\n",
       "      <td>0.066214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.365381</td>\n",
       "      <td>0.175198</td>\n",
       "      <td>0.233734</td>\n",
       "      <td>0.230603</td>\n",
       "      <td>0.154447</td>\n",
       "      <td>0.125233</td>\n",
       "      <td>0.182839</td>\n",
       "      <td>0.446325</td>\n",
       "      <td>0.805794</td>\n",
       "      <td>0.380621</td>\n",
       "      <td>0.127164</td>\n",
       "      <td>0.208606</td>\n",
       "      <td>0.426908</td>\n",
       "      <td>0.020711</td>\n",
       "      <td>0.238079</td>\n",
       "      <td>0.071783</td>\n",
       "      <td>0.081577</td>\n",
       "      <td>0.067003</td>\n",
       "      <td>0.199035</td>\n",
       "      <td>0.223704</td>\n",
       "      <td>0.207602</td>\n",
       "      <td>0.063678</td>\n",
       "      <td>0.223355</td>\n",
       "      <td>0.209076</td>\n",
       "      <td>0.189759</td>\n",
       "      <td>0.204944</td>\n",
       "      <td>0.341722</td>\n",
       "      <td>0.204727</td>\n",
       "      <td>0.348571</td>\n",
       "      <td>0.318086</td>\n",
       "      <td>0.177841</td>\n",
       "      <td>0.183011</td>\n",
       "      <td>0.207380</td>\n",
       "      <td>0.257704</td>\n",
       "      <td>0.115585</td>\n",
       "      <td>0.271708</td>\n",
       "      <td>0.007019</td>\n",
       "      <td>0.106703</td>\n",
       "      <td>0.306342</td>\n",
       "      <td>0.382994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.047407</td>\n",
       "      <td>0.856744</td>\n",
       "      <td>0.066668</td>\n",
       "      <td>0.046414</td>\n",
       "      <td>0.654683</td>\n",
       "      <td>0.442411</td>\n",
       "      <td>0.044354</td>\n",
       "      <td>0.841770</td>\n",
       "      <td>0.719654</td>\n",
       "      <td>0.133001</td>\n",
       "      <td>0.639230</td>\n",
       "      <td>0.065401</td>\n",
       "      <td>0.003770</td>\n",
       "      <td>0.656466</td>\n",
       "      <td>0.061181</td>\n",
       "      <td>0.018879</td>\n",
       "      <td>0.713081</td>\n",
       "      <td>0.710977</td>\n",
       "      <td>0.652039</td>\n",
       "      <td>0.802149</td>\n",
       "      <td>0.713393</td>\n",
       "      <td>0.738163</td>\n",
       "      <td>0.024050</td>\n",
       "      <td>0.825086</td>\n",
       "      <td>0.754566</td>\n",
       "      <td>0.846251</td>\n",
       "      <td>0.842834</td>\n",
       "      <td>0.746928</td>\n",
       "      <td>0.865909</td>\n",
       "      <td>0.682754</td>\n",
       "      <td>0.021553</td>\n",
       "      <td>0.042277</td>\n",
       "      <td>0.789656</td>\n",
       "      <td>0.848372</td>\n",
       "      <td>0.038664</td>\n",
       "      <td>0.156200</td>\n",
       "      <td>0.029353</td>\n",
       "      <td>0.817556</td>\n",
       "      <td>0.014326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.654965</td>\n",
       "      <td>0.583945</td>\n",
       "      <td>0.717332</td>\n",
       "      <td>0.035134</td>\n",
       "      <td>0.060924</td>\n",
       "      <td>0.036549</td>\n",
       "      <td>0.049155</td>\n",
       "      <td>0.811794</td>\n",
       "      <td>0.847691</td>\n",
       "      <td>0.635823</td>\n",
       "      <td>0.027131</td>\n",
       "      <td>0.040872</td>\n",
       "      <td>0.774282</td>\n",
       "      <td>0.020331</td>\n",
       "      <td>0.877778</td>\n",
       "      <td>0.929009</td>\n",
       "      <td>0.106039</td>\n",
       "      <td>0.019663</td>\n",
       "      <td>0.789611</td>\n",
       "      <td>0.686795</td>\n",
       "      <td>0.672481</td>\n",
       "      <td>0.025384</td>\n",
       "      <td>0.702995</td>\n",
       "      <td>0.051921</td>\n",
       "      <td>0.598549</td>\n",
       "      <td>0.758062</td>\n",
       "      <td>0.665601</td>\n",
       "      <td>0.862356</td>\n",
       "      <td>0.805011</td>\n",
       "      <td>0.689778</td>\n",
       "      <td>0.035593</td>\n",
       "      <td>0.665647</td>\n",
       "      <td>0.749958</td>\n",
       "      <td>0.017688</td>\n",
       "      <td>0.026764</td>\n",
       "      <td>0.086354</td>\n",
       "      <td>0.003828</td>\n",
       "      <td>0.036413</td>\n",
       "      <td>0.112572</td>\n",
       "      <td>0.736643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.012602</td>\n",
       "      <td>0.711812</td>\n",
       "      <td>0.071569</td>\n",
       "      <td>0.044851</td>\n",
       "      <td>0.708731</td>\n",
       "      <td>0.362941</td>\n",
       "      <td>0.040776</td>\n",
       "      <td>0.480433</td>\n",
       "      <td>0.584040</td>\n",
       "      <td>0.060250</td>\n",
       "      <td>0.736261</td>\n",
       "      <td>0.048488</td>\n",
       "      <td>0.032048</td>\n",
       "      <td>0.904479</td>\n",
       "      <td>0.064298</td>\n",
       "      <td>0.022738</td>\n",
       "      <td>0.540619</td>\n",
       "      <td>0.562304</td>\n",
       "      <td>0.881918</td>\n",
       "      <td>0.842282</td>\n",
       "      <td>0.710248</td>\n",
       "      <td>0.709233</td>\n",
       "      <td>0.019294</td>\n",
       "      <td>0.712840</td>\n",
       "      <td>0.934187</td>\n",
       "      <td>0.754544</td>\n",
       "      <td>0.737463</td>\n",
       "      <td>0.868673</td>\n",
       "      <td>0.311979</td>\n",
       "      <td>0.928508</td>\n",
       "      <td>0.030664</td>\n",
       "      <td>0.060964</td>\n",
       "      <td>0.767515</td>\n",
       "      <td>0.602867</td>\n",
       "      <td>0.031160</td>\n",
       "      <td>0.023415</td>\n",
       "      <td>0.066440</td>\n",
       "      <td>0.631997</td>\n",
       "      <td>0.019464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929188</td>\n",
       "      <td>0.746774</td>\n",
       "      <td>0.675822</td>\n",
       "      <td>0.007927</td>\n",
       "      <td>0.038571</td>\n",
       "      <td>0.025504</td>\n",
       "      <td>0.008351</td>\n",
       "      <td>0.927918</td>\n",
       "      <td>0.827824</td>\n",
       "      <td>0.918143</td>\n",
       "      <td>0.045404</td>\n",
       "      <td>0.038814</td>\n",
       "      <td>0.835670</td>\n",
       "      <td>0.049485</td>\n",
       "      <td>0.655468</td>\n",
       "      <td>0.537027</td>\n",
       "      <td>0.034726</td>\n",
       "      <td>0.027015</td>\n",
       "      <td>0.569623</td>\n",
       "      <td>0.785604</td>\n",
       "      <td>0.898315</td>\n",
       "      <td>0.018262</td>\n",
       "      <td>0.839751</td>\n",
       "      <td>0.032901</td>\n",
       "      <td>0.721045</td>\n",
       "      <td>0.605482</td>\n",
       "      <td>0.948713</td>\n",
       "      <td>0.570968</td>\n",
       "      <td>0.847235</td>\n",
       "      <td>0.794699</td>\n",
       "      <td>0.029819</td>\n",
       "      <td>0.919816</td>\n",
       "      <td>0.827702</td>\n",
       "      <td>0.027208</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>0.057312</td>\n",
       "      <td>0.008514</td>\n",
       "      <td>0.025699</td>\n",
       "      <td>0.025907</td>\n",
       "      <td>0.630518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         0         1    ...           97        98        99\n",
       "0   0  0.052900  0.025055    ...     0.539237  0.533372  0.063803\n",
       "1   1  0.013695  0.145779    ...     0.069366  0.059980  0.576983\n",
       "2   2  0.072572  0.104996    ...     0.106703  0.306342  0.382994\n",
       "3   3  0.047407  0.856744    ...     0.036413  0.112572  0.736643\n",
       "4   4  0.012602  0.711812    ...     0.025699  0.025907  0.630518\n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"train_16_multi_merge_dropout.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JfiWXVciVt-b"
   },
   "outputs": [],
   "source": [
    "test_16.to_csv(\"test_16_multi_merge_dropout.csv\",index=False)\n",
    "test_1.to_csv(\"test_1_multi_merge_dropout.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Multiple Concat + Dropout.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
