{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture A - Multi Concat Functions with Dropout and Using Word2Vec Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Architecture-A---Multi-Concat-Functions-with-Dropout-and-Using-Word2Vec-Embedding\" data-toc-modified-id=\"Architecture-A---Multi-Concat-Functions-with-Dropout-and-Using-Word2Vec-Embedding-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Architecture A - Multi Concat Functions with Dropout and Using Word2Vec Embedding</a></span></li><li><span><a href=\"#Download-libraries-for-Google-Colab-and-Download-Embeddings\" data-toc-modified-id=\"Download-libraries-for-Google-Colab-and-Download-Embeddings-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Download libraries for Google Colab and Download Embeddings</a></span></li><li><span><a href=\"#Import-Data\" data-toc-modified-id=\"Import-Data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Import Data</a></span></li><li><span><a href=\"#Load-Embedding-and-Create-Embedding-Layer\" data-toc-modified-id=\"Load-Embedding-and-Create-Embedding-Layer-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Load Embedding and Create Embedding Layer</a></span></li><li><span><a href=\"#Define-and-Train-Network\" data-toc-modified-id=\"Define-and-Train-Network-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Define and Train Network</a></span></li><li><span><a href=\"#Pass-Train-and-Test-Data-Through-Network-and-Save-for-Stacking\" data-toc-modified-id=\"Pass-Train-and-Test-Data-Through-Network-and-Save-for-Stacking-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Pass Train and Test Data Through Network and Save for Stacking</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7f1fc879ae2f51de5ee911e8119a373b1ba4fbf0",
    "colab_type": "text",
    "id": "x5C57FHH8Rkn"
   },
   "source": [
    "# Download libraries for Google Colab and Download Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "cZk-JGeTFa_0",
    "outputId": "ca32dc9c-fd39-49dd-e7f9-ab560d3cfc0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==0.23.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/d8/feeb346d41f181e83fba45224ab14a8d8af019b48af742e047f3845d8cff/pandas-0.23.4-cp36-cp36m-manylinux1_x86_64.whl (8.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 8.9MB 3.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.23.4) (2.5.3)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.23.4) (1.14.6)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.23.4) (2018.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas==0.23.4) (1.11.0)\n",
      "\u001b[31mcufflinks 0.14.6 has requirement plotly>=3.0.0, but you'll have plotly 1.12.12 which is incompatible.\u001b[0m\n",
      "Installing collected packages: pandas\n",
      "  Found existing installation: pandas 0.22.0\n",
      "    Uninstalling pandas-0.22.0:\n",
      "      Successfully uninstalled pandas-0.22.0\n",
      "Successfully installed pandas-0.23.4\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas==0.23.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qDR834FhFoYI",
    "outputId": "f887224a-90fa-48c1-a5aa-702004b8ae7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.22.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "bSjcF-ie9vqH",
    "outputId": "44ae39f9-50fd-47e6-8369-98af60266a49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-12-12 23:02:59--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.232.61\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.232.61|:443... connected.\n",
      "HTTP request sent, awaiting response... 206 Partial Content\n",
      "Length: 1647046227 (1.5G), 648801875 (619M) remaining [application/x-gzip]\n",
      "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
      "\n",
      "GoogleNews-vectors- 100%[++++++++++++=======>]   1.53G  41.3MB/s    in 15s     \n",
      "\n",
      "2018-12-12 23:03:14 (41.3 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EKVjdxnm-5jV"
   },
   "outputs": [],
   "source": [
    "! gunzip GoogleNews-vectors-negative300.bin.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cAxe2i-G-_aI"
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:22:06.696094Z",
     "start_time": "2018-12-03T07:22:06.268835Z"
    },
    "_uuid": "cbd07f9d34f86a58595067c6f1dccb39850527cc",
    "colab": {},
    "colab_type": "code",
    "id": "u9oY0ixH8Rkq",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hwyhbYREgkRe",
    "outputId": "36a68dfb-9784-4017-ccb5-8edf05bd8cf4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v5FdaALfgvYk"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train_data.csv\",doublequote=True,quotechar='\"',sep=\",\").drop(\"is_duplicate\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:22:07.748093Z",
     "start_time": "2018-12-03T07:22:07.630284Z"
    },
    "_uuid": "22768bf18f84f81d6de2cccc0853ee03c4985772",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "CEtdLpDn8RlE",
    "outputId": "c7297862-2c34-4fc9-b77d-04d4e9447978"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  is_duplicate\n",
       "0   0             0\n",
       "1   1             0\n",
       "2   2             0\n",
       "3   3             0\n",
       "4   4             0"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t_labels= pd.read_csv('train_labels.csv', encoding='utf-8')\n",
    "df_t_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:22:08.109493Z",
     "start_time": "2018-12-03T07:22:07.751733Z"
    },
    "_uuid": "082e1aa70a2c860a81ffa5d0820407aff9a285f4",
    "colab": {},
    "colab_type": "code",
    "id": "wFoa62bD8RlI"
   },
   "outputs": [],
   "source": [
    "df_train = df_train.merge(df_t_labels,on=[\"id\"],how=\"inner\")\n",
    "df_train.head()\n",
    "df_train['id'] = df_train['id'].apply(str)\n",
    "df_train['is_duplicate'] = df_train['is_duplicate'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:22:08.281182Z",
     "start_time": "2018-12-03T07:22:08.140777Z"
    },
    "_uuid": "5b646581d786a7e45d5e7f0cedcfd9fafeac3552",
    "colab": {},
    "colab_type": "code",
    "id": "BPoyvIb_8RlR"
   },
   "outputs": [],
   "source": [
    "df_train['question1'].fillna('', inplace=True)\n",
    "df_train['question2'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dNIJKeiAF5hf",
    "outputId": "04d3cf72-595f-467b-a0b3-210d95c4e4a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.4'"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:22:08.522485Z",
     "start_time": "2018-12-03T07:22:08.283282Z"
    },
    "_uuid": "82c5dfe1ed458b7bbf336b3be0485c5faf588dd5",
    "colab": {},
    "colab_type": "code",
    "id": "GBj-sEeG8RlU"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_data.csv',doublequote=True)\n",
    "df_test['test_id'] = df_test['test_id'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:22:08.911150Z",
     "start_time": "2018-12-03T07:22:08.524588Z"
    },
    "_uuid": "e6e75ae38bcae9d418a3616bf712d1c457afad43",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "nOpryMQc8RlX",
    "outputId": "667aee5d-16cf-48d2-c8ba-608356bec6e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.concat((df_train, df_test))\n",
    "df_all['question1'].fillna('', inplace=True)\n",
    "df_all['question2'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:22:09.298149Z",
     "start_time": "2018-12-03T07:22:08.930018Z"
    },
    "_uuid": "3c844458d3b15d6e9692cabc783d568a793b0000",
    "colab": {},
    "colab_type": "code",
    "id": "Gto3hCeC8Rlh"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:22:21.640288Z",
     "start_time": "2018-12-03T07:22:09.300685Z"
    },
    "_uuid": "1441257c592632854f5bb2eefefe62e2ffeeb8b4",
    "colab": {},
    "colab_type": "code",
    "id": "YPYeAHEw8Rlk"
   },
   "outputs": [],
   "source": [
    "counts_vectorizer = CountVectorizer(max_features=10000-1).fit(\n",
    "    itertools.chain(df_all['question1'], df_all['question2']))\n",
    "\n",
    "other_index = len(counts_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:22:23.303725Z",
     "start_time": "2018-12-03T07:22:21.641852Z"
    },
    "_uuid": "eef9b41700c8545288afb21acc249a61ba36deac",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "LHHo2dRN8Rlo",
    "outputId": "5ed6b293-9e4d-4642-95fb-eb4d599f2ec6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras \n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:22:23.309534Z",
     "start_time": "2018-12-03T07:22:23.305897Z"
    },
    "_uuid": "1b0456d3899305fa68a305c44ac143b38a324d1c",
    "colab": {},
    "colab_type": "code",
    "id": "B8-xp-i_8Rlr"
   },
   "outputs": [],
   "source": [
    "words_tokenizer = re.compile(counts_vectorizer.token_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:22:23.322370Z",
     "start_time": "2018-12-03T07:22:23.312029Z"
    },
    "_uuid": "eba36585ada62745fd9494559ec265e45344a8e3",
    "colab": {},
    "colab_type": "code",
    "id": "htDh1abY8Rlx"
   },
   "outputs": [],
   "source": [
    "def create_padded_seqs(texts, max_len=30):\n",
    "    seqs = texts.apply(lambda s: \n",
    "        [counts_vectorizer.vocabulary_[w] if w in counts_vectorizer.vocabulary_ else other_index\n",
    "         for w in words_tokenizer.findall(s.lower())])\n",
    "    return pad_sequences(seqs, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WwbjDiODTxBp"
   },
   "outputs": [],
   "source": [
    "nlp_train_df = pd.read_csv(\"train_features_31.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "fXfP2oP7fRCu",
    "outputId": "b07fc65e-33f8-443a-fce4-671dfa43a6aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(323164, 31)\n",
      "(323164, 32)\n"
     ]
    }
   ],
   "source": [
    "print(nlp_train_df.drop(\"id\",axis=1).shape)\n",
    "print(nlp_train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:22:35.799021Z",
     "start_time": "2018-12-03T07:22:23.324561Z"
    },
    "_uuid": "b130f6a4dadcf25e245e63a2e99cb06b5356d74d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "gZOZtXRl8Rl6",
    "outputId": "527da958-c1b5-45df-be11-105faebadf25"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "X1_train, X1_val, X2_train, X2_val, y_train, y_val, train_id, train_val_id, nlp_train, nlp_val= \\\n",
    "    train_test_split(create_padded_seqs(df_train['question1']),\n",
    "                     create_padded_seqs(df_train['question2']),\n",
    "                     df_train['is_duplicate'].values,\n",
    "                     df_train.id,\n",
    "                     nlp_train_df.drop(\"id\",axis=1).as_matrix(),\n",
    "                     stratify=df_train['is_duplicate'].values,\n",
    "                     test_size=0.3, random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g4a0X0CZMBYX"
   },
   "outputs": [],
   "source": [
    "train_id_pd = pd.DataFrame(train_id.values)\n",
    "train_val_id_pd = pd.DataFrame(train_val_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O9Nuk3zDN1oF"
   },
   "outputs": [],
   "source": [
    "train_id_pd.to_csv(\"train_id_multiple_merge_dropout_word2vec.csv\",index=False)\n",
    "train_val_id_pd.to_csv(\"train_val_id_multiple_merge_dropout_word2vec.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "baa0cdb1a6f3d43d9c10d8994ac323ca8675304d",
    "colab_type": "text",
    "id": "3gGVTptx8Rl_"
   },
   "source": [
    "# Load Embedding and Create Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:23:12.888232Z",
     "start_time": "2018-12-03T07:22:35.800623Z"
    },
    "_uuid": "d776d24783e3b723eb6c49a660ccba00891c0c2b",
    "colab": {},
    "colab_type": "code",
    "id": "DqmZ_sWh8RmA"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "word_vectors = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "EMBEDDING_DIM=300\n",
    "NUM_WORDS= 10000\n",
    "word_index = counts_vectorizer.vocabulary_\n",
    "\n",
    "vocabulary_size=min(len(word_index)+1,NUM_WORDS)\n",
    "\n",
    "\n",
    "embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:23:12.939567Z",
     "start_time": "2018-12-03T07:23:12.890096Z"
    },
    "_uuid": "6bd2dc8d80c5d1625b52e25bb7e3d9159e2d02fa",
    "colab": {},
    "colab_type": "code",
    "id": "17E4B_WC8RmI"
   },
   "outputs": [],
   "source": [
    "for word, i in word_index.items():\n",
    "    if i>=NUM_WORDS:\n",
    "        continue\n",
    "    try:\n",
    "        embedding_vector = word_vectors[word]\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except KeyError:\n",
    "        embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)\n",
    "\n",
    "del(word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lbC54-RU0Orv",
    "outputId": "134ce63f-0a18-4203-a361-3c12ffaa3616"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 300)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:23:12.968662Z",
     "start_time": "2018-12-03T07:23:12.946336Z"
    },
    "_uuid": "dd550fd808132fc4454ce689155dfe6ca6b27b6c",
    "colab": {},
    "colab_type": "code",
    "id": "D6bJONe18RmM"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = X1_train.shape[1]\n",
    "\n",
    "from keras.layers import Embedding\n",
    "embedding_layer = Embedding(vocabulary_size,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a0744cffaf5770637c89c8f3649b48e625470ef0",
    "colab_type": "text",
    "id": "yRbk0yJQ8RmQ"
   },
   "source": [
    "# Define and Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "996a9458e8adaf6f9da175d2ad46d0a856a60172",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tQwhw1T08RmR",
    "outputId": "b5b22e36-0b19-4adc-c920-126dbfba8586"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:23:12.973807Z",
     "start_time": "2018-12-03T07:23:12.971013Z"
    },
    "_uuid": "3e30e0fa371ddafe97293abbd88d617d8fc39b1b",
    "colab": {},
    "colab_type": "code",
    "id": "-koH4sSU8RmV"
   },
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "id": "wmFFxAo2vWNx",
    "outputId": "8e0d8c96-c39a-4c5e-e98a-977cff31910c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 30, 300)      3000000     input_15[0][0]                   \n",
      "                                                                 input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   (None, 256)          570368      embedding_2[0][0]                \n",
      "                                                                 embedding_2[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256)          1024        lstm_8[0][0]                     \n",
      "                                                                 lstm_8[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 256)          0           batch_normalization_3[6][0]      \n",
      "                                                                 batch_normalization_3[7][0]      \n",
      "__________________________________________________________________________________________________\n",
      "subtract_8 (Subtract)           (None, 256)          0           batch_normalization_3[6][0]      \n",
      "                                                                 batch_normalization_3[7][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 256)          0           batch_normalization_3[6][0]      \n",
      "                                                                 batch_normalization_3[7][0]      \n",
      "__________________________________________________________________________________________________\n",
      "maximum_8 (Maximum)             (None, 256)          0           batch_normalization_3[6][0]      \n",
      "                                                                 batch_normalization_3[7][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1024)         0           multiply_8[0][0]                 \n",
      "                                                                 subtract_8[0][0]                 \n",
      "                                                                 add_8[0][0]                      \n",
      "                                                                 maximum_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 1024)         0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 100)          102500      dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 100)          0           dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 100)          10100       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 1)            101         dense_23[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,684,093\n",
      "Trainable params: 683,581\n",
      "Non-trainable params: 3,000,512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "words_embedding_layer = embedding_layer\n",
    "seq_embedding_layer = LSTM(256, activation='tanh')\n",
    "\n",
    "input1_tensor = Input(X1_train.shape[1:])\n",
    "input2_tensor = Input(X2_train.shape[1:])\n",
    "\n",
    "words_embedding_layer1 = words_embedding_layer(input1_tensor)\n",
    "words_embedding_layer2 = words_embedding_layer(input2_tensor)\n",
    "\n",
    "seq_embedding_layer1 = seq_embedding_layer(words_embedding_layer1) \n",
    "seq_embedding_layer2 = seq_embedding_layer(words_embedding_layer2)\n",
    "\n",
    "norm_seq_embedding_layer1 = batch_norm(seq_embedding_layer1)\n",
    "norm_seq_embedding_layer2 = batch_norm(seq_embedding_layer2)\n",
    "\n",
    "\n",
    "multiply_merge = multiply([norm_seq_embedding_layer1, norm_seq_embedding_layer2])\n",
    "\n",
    "sub_merge = subtract([norm_seq_embedding_layer1, norm_seq_embedding_layer2])\n",
    "\n",
    "add_merge = add([norm_seq_embedding_layer1, norm_seq_embedding_layer2])\n",
    "\n",
    "max_merge = maximum([norm_seq_embedding_layer1, norm_seq_embedding_layer2])\n",
    "\n",
    "merge_layer = concatenate([multiply_merge, sub_merge, add_merge,max_merge])\n",
    "\n",
    "dropout1 = Dropout(0.15)(merge_layer)\n",
    "\n",
    "dense1_layer = Dense(100, activation='sigmoid')(dropout1)\n",
    "\n",
    "dropout2 = Dropout(0.15)(dense1_layer)\n",
    "\n",
    "dense2_layer = Dense(100, activation='sigmoid')(dropout2)\n",
    "\n",
    "\n",
    "ouput_layer = Dense(1, activation='sigmoid')(dense2_layer)\n",
    "\n",
    "model = Model([input1_tensor, input2_tensor], ouput_layer)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QhoUwlrQ4ldv"
   },
   "outputs": [],
   "source": [
    "# with 300d\n",
    "#Epoch 00003: val_loss improved from 0.42090 to 0.39988, saving model to weights.best.Siamese.gloverLSTM256\n",
    "#Epoch 4/5\n",
    "#226214/226214 [==============================] - 329s 1ms/step - loss: 0.3274 - acc: 0.8537 - val_loss: 0.3956 - val_acc: 0.8191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Z0qv4cAgPhAT",
    "outputId": "fa71b8f5-13f0-40f1-b24b-470d164bd8ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘weights.LSTM256.multiple.merge.word2vec’: File exists\n"
     ]
    }
   ],
   "source": [
    "! mkdir weights.LSTM256.multiple.merge.word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "bbc5078a16a2fabc4601d25e90c205af8edacb5e",
    "colab": {},
    "colab_type": "code",
    "id": "EzlbYMKw8Rmn"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "\n",
    "directory = \"weights.LSTM256.multiple.merge.word2vec/dropout.{epoch:02d}-{loss:.2f}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=directory, \n",
    "                               verbose=1, save_best_only=False,monitor=\"val_loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "gpfRoPtR3cWm",
    "outputId": "4d0513fe-921e-4aef-eff7-236a4a7ec996"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 226214 samples, validate on 96950 samples\n",
      "Epoch 1/4\n",
      "226214/226214 [==============================] - 364s 2ms/step - loss: 0.4673 - acc: 0.7692 - val_loss: 0.4354 - val_acc: 0.7914\n",
      "\n",
      "Epoch 00001: saving model to weights.LSTM256.multiple.merge.word2vec/dropout.01-0.47-0.44.hdf5\n",
      "Epoch 2/4\n",
      "226214/226214 [==============================] - 358s 2ms/step - loss: 0.3949 - acc: 0.8124 - val_loss: 0.4078 - val_acc: 0.8048\n",
      "\n",
      "Epoch 00002: saving model to weights.LSTM256.multiple.merge.word2vec/dropout.02-0.39-0.41.hdf5\n",
      "Epoch 3/4\n",
      "226214/226214 [==============================] - 356s 2ms/step - loss: 0.3532 - acc: 0.8361 - val_loss: 0.3857 - val_acc: 0.8180\n",
      "\n",
      "Epoch 00003: saving model to weights.LSTM256.multiple.merge.word2vec/dropout.03-0.35-0.39.hdf5\n",
      "Epoch 4/4\n",
      "226214/226214 [==============================] - 355s 2ms/step - loss: 0.3185 - acc: 0.8552 - val_loss: 0.3746 - val_acc: 0.8279\n",
      "\n",
      "Epoch 00004: saving model to weights.LSTM256.multiple.merge.word2vec/dropout.04-0.32-0.37.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd12d504e10>"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X1_train, X2_train], \n",
    "          y_train, \n",
    "            batch_size=128, \n",
    "            epochs=4,\n",
    "            callbacks=[checkpointer],\n",
    "            validation_data=([X1_val, X2_val], y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EBeMwQ2G3cS9"
   },
   "outputs": [],
   "source": [
    "#Train on 226214 samples, validate on 96950 samples\n",
    "#Train on 226214 samples, validate on 96950 samples\n",
    "#Epoch 1/4\n",
    "#226214/226214 [==============================] - 364s 2ms/step - loss: 0.4673 - acc: 0.7692 - val_loss: 0.4354 - val_acc: 0.7914\n",
    "#\n",
    "#Epoch 00001: saving model to weights.LSTM256.multiple.merge.word2vec/dropout.01-0.47-0.44.hdf5\n",
    "#Epoch 2/4\n",
    "#226214/226214 [==============================] - 358s 2ms/step - loss: 0.3949 - acc: 0.8124 - val_loss: 0.4078 - val_acc: 0.8048\n",
    "#\n",
    "#Epoch 00002: saving model to weights.LSTM256.multiple.merge.word2vec/dropout.02-0.39-0.41.hdf5\n",
    "#Epoch 3/4\n",
    "#226214/226214 [==============================] - 356s 2ms/step - loss: 0.3532 - acc: 0.8361 - val_loss: 0.3857 - val_acc: 0.8180\n",
    "#\n",
    "#Epoch 00003: saving model to weights.LSTM256.multiple.merge.word2vec/dropout.03-0.35-0.39.hdf5\n",
    "#Epoch 4/4\n",
    "#226214/226214 [==============================] - 355s 2ms/step - loss: 0.3185 - acc: 0.8552 - val_loss: 0.3746 - val_acc: 0.8279\n",
    "#\n",
    "#Epoch 00004: saving model to weights.LSTM256.multiple.merge.word2vec/dropout.04-0.32-0.37.hdf5\n",
    "#<keras.callbacks.History at 0x7fd12d504e10>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6IBEWMmF3cMu"
   },
   "outputs": [],
   "source": [
    "# Load Best Epoch\n",
    "model.load_weights(\"weights.LSTM256.multiple.merge.word2vec/dropout.03-0.35-0.39.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J_JyLaqxTJ62"
   },
   "source": [
    "# Pass Train and Test Data Through Network and Save for Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HzBIv6HdTHZs"
   },
   "outputs": [],
   "source": [
    "#features_model_512 = Model([input1_tensor, input2_tensor], merge_layer)\n",
    "#features_model_512.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F4rjd3K9T2s3"
   },
   "outputs": [],
   "source": [
    "features_model_16 = Model([input1_tensor, input2_tensor], dense1_layer)\n",
    "features_model_16.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zj1cDtIQixvu"
   },
   "outputs": [],
   "source": [
    "train_preds = [create_padded_seqs(df_train['question1']),create_padded_seqs(df_train['question2'])]\n",
    "test_preds = [create_padded_seqs(df_test['question1']),create_padded_seqs(df_test['question2'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qjizSpq6T2V_"
   },
   "outputs": [],
   "source": [
    "F_train_16 = features_model_16.predict(train_preds, batch_size=128)\n",
    "F_test_16 = features_model_16.predict(test_preds, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hbMiNLdYjVZ_"
   },
   "outputs": [],
   "source": [
    "F_train_1 = model.predict(train_preds, batch_size=128)\n",
    "F_test_1 = model.predict(test_preds, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ieHj5UAb1zJz"
   },
   "outputs": [],
   "source": [
    "test_1 = pd.concat([df_test.test_id,pd.DataFrame(F_test_1)],axis=1)\n",
    "test_16 = pd.concat([df_test.test_id,pd.DataFrame(F_test_16)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "Yq_UWyDh2aoA",
    "outputId": "01cab924-e930-4c8c-bcb9-d6dcd4162cc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81126, 2)\n",
      "(81126, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>...</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>0.193592</td>\n",
       "      <td>0.005574</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>0.993908</td>\n",
       "      <td>0.338313</td>\n",
       "      <td>0.723192</td>\n",
       "      <td>0.795046</td>\n",
       "      <td>0.00223</td>\n",
       "      <td>0.158854</td>\n",
       "      <td>0.988268</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.007147</td>\n",
       "      <td>0.451349</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.218361</td>\n",
       "      <td>0.002545</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.18982</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>2.927827e-08</td>\n",
       "      <td>0.606357</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.038797e-07</td>\n",
       "      <td>0.012725</td>\n",
       "      <td>0.942089</td>\n",
       "      <td>0.243378</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.009669</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.013546</td>\n",
       "      <td>0.998158</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.057761</td>\n",
       "      <td>0.017171</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995264</td>\n",
       "      <td>1.028949e-07</td>\n",
       "      <td>0.013369</td>\n",
       "      <td>0.00278</td>\n",
       "      <td>0.101534</td>\n",
       "      <td>0.955251</td>\n",
       "      <td>0.997745</td>\n",
       "      <td>0.451523</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.104227</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>2.279523e-07</td>\n",
       "      <td>0.99782</td>\n",
       "      <td>0.990574</td>\n",
       "      <td>0.351793</td>\n",
       "      <td>0.036958</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.112098</td>\n",
       "      <td>0.998474</td>\n",
       "      <td>0.00014</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.998801</td>\n",
       "      <td>0.871266</td>\n",
       "      <td>0.858014</td>\n",
       "      <td>0.8965</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.985471</td>\n",
       "      <td>0.162734</td>\n",
       "      <td>2.359971e-07</td>\n",
       "      <td>0.004697</td>\n",
       "      <td>0.033329</td>\n",
       "      <td>4.848347e-07</td>\n",
       "      <td>0.982954</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.00162</td>\n",
       "      <td>0.998611</td>\n",
       "      <td>0.963799</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.99841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  test_id         0         1   ...           97       98       99\n",
       "0      15  0.193592  0.005574   ...     0.001922  0.00044  0.99841\n",
       "\n",
       "[1 rows x 101 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_1.shape)\n",
    "print(df_test.shape)\n",
    "test_16.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-IPCS8f42HOH"
   },
   "outputs": [],
   "source": [
    "train_1 = pd.concat([df_train.id,pd.DataFrame(F_train_1)],axis=1)\n",
    "train_16 = pd.concat([df_train.id,pd.DataFrame(F_train_16)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "QHwBQUvl2zgu",
    "outputId": "24526bd0-ef05-4333-fc95-1b7a45657233"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(323164, 2)\n",
      "(323164, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>...</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.187019</td>\n",
       "      <td>0.339917</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.081118</td>\n",
       "      <td>0.408207</td>\n",
       "      <td>0.83827</td>\n",
       "      <td>0.356676</td>\n",
       "      <td>0.003912</td>\n",
       "      <td>0.021298</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.024902</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.004094</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.005132</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.009388</td>\n",
       "      <td>0.985914</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.998812</td>\n",
       "      <td>0.556846</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.180587</td>\n",
       "      <td>0.84744</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.958627</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006933</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.396937</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.548771</td>\n",
       "      <td>0.336816</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.005035</td>\n",
       "      <td>0.024591</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>0.255509</td>\n",
       "      <td>0.084327</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>2.104622e-07</td>\n",
       "      <td>0.003387</td>\n",
       "      <td>0.018401</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.981612</td>\n",
       "      <td>0.991896</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>9.054973e-07</td>\n",
       "      <td>0.005581</td>\n",
       "      <td>0.598334</td>\n",
       "      <td>0.005106</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.007305</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.27108</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.289869</td>\n",
       "      <td>0.860059</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.998583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id         0         1    ...           97        98        99\n",
       "0  0  0.187019  0.339917    ...     0.000668  0.000604  0.998583\n",
       "\n",
       "[1 rows x 101 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_1.shape)\n",
    "print(df_train.shape)\n",
    "train_16.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tmo1rBgB34z5"
   },
   "outputs": [],
   "source": [
    "train_16.to_csv(\"train_100_multi_merge_dropout_word2vec.csv\",index=False)\n",
    "train_1.to_csv(\"train_1_merge_dropout_word2vec.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "oHVbD1-sPgqp",
    "outputId": "6517f826-d1d6-422c-ba88-0669d683b256"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>...</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>0.073420</td>\n",
       "      <td>0.127493</td>\n",
       "      <td>0.204640</td>\n",
       "      <td>0.040163</td>\n",
       "      <td>0.152333</td>\n",
       "      <td>0.102389</td>\n",
       "      <td>0.036234</td>\n",
       "      <td>0.111532</td>\n",
       "      <td>0.028089</td>\n",
       "      <td>0.150028</td>\n",
       "      <td>0.048816</td>\n",
       "      <td>0.031324</td>\n",
       "      <td>0.052991</td>\n",
       "      <td>0.036564</td>\n",
       "      <td>0.068313</td>\n",
       "      <td>0.054790</td>\n",
       "      <td>0.169379</td>\n",
       "      <td>0.091560</td>\n",
       "      <td>0.041190</td>\n",
       "      <td>0.020220</td>\n",
       "      <td>0.019513</td>\n",
       "      <td>0.026912</td>\n",
       "      <td>0.084623</td>\n",
       "      <td>0.103742</td>\n",
       "      <td>0.060157</td>\n",
       "      <td>0.006674</td>\n",
       "      <td>0.116495</td>\n",
       "      <td>0.020345</td>\n",
       "      <td>0.218703</td>\n",
       "      <td>0.362897</td>\n",
       "      <td>0.023856</td>\n",
       "      <td>0.099030</td>\n",
       "      <td>0.259389</td>\n",
       "      <td>0.175478</td>\n",
       "      <td>0.030123</td>\n",
       "      <td>0.180475</td>\n",
       "      <td>0.034675</td>\n",
       "      <td>0.102020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044497</td>\n",
       "      <td>0.024875</td>\n",
       "      <td>0.100500</td>\n",
       "      <td>0.133805</td>\n",
       "      <td>0.085602</td>\n",
       "      <td>0.059995</td>\n",
       "      <td>0.051828</td>\n",
       "      <td>0.035246</td>\n",
       "      <td>0.014621</td>\n",
       "      <td>0.365312</td>\n",
       "      <td>0.333340</td>\n",
       "      <td>0.034149</td>\n",
       "      <td>0.009329</td>\n",
       "      <td>0.071517</td>\n",
       "      <td>0.067056</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>0.018455</td>\n",
       "      <td>0.013533</td>\n",
       "      <td>0.059220</td>\n",
       "      <td>0.087057</td>\n",
       "      <td>0.096042</td>\n",
       "      <td>0.227474</td>\n",
       "      <td>0.030402</td>\n",
       "      <td>0.014630</td>\n",
       "      <td>0.117645</td>\n",
       "      <td>0.103173</td>\n",
       "      <td>0.086414</td>\n",
       "      <td>0.194886</td>\n",
       "      <td>0.028696</td>\n",
       "      <td>0.014988</td>\n",
       "      <td>0.018165</td>\n",
       "      <td>0.021553</td>\n",
       "      <td>0.070063</td>\n",
       "      <td>0.010757</td>\n",
       "      <td>0.017155</td>\n",
       "      <td>0.030942</td>\n",
       "      <td>0.177486</td>\n",
       "      <td>0.027851</td>\n",
       "      <td>0.007006</td>\n",
       "      <td>0.022598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.897088</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.338341</td>\n",
       "      <td>0.660417</td>\n",
       "      <td>0.001525</td>\n",
       "      <td>0.853235</td>\n",
       "      <td>0.623497</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>0.169963</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.445844</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>0.944412</td>\n",
       "      <td>0.623338</td>\n",
       "      <td>0.750383</td>\n",
       "      <td>0.315461</td>\n",
       "      <td>0.520308</td>\n",
       "      <td>0.008011</td>\n",
       "      <td>0.605156</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.499908</td>\n",
       "      <td>0.008825</td>\n",
       "      <td>0.115254</td>\n",
       "      <td>0.827936</td>\n",
       "      <td>0.954568</td>\n",
       "      <td>0.528000</td>\n",
       "      <td>0.008182</td>\n",
       "      <td>0.602005</td>\n",
       "      <td>0.152116</td>\n",
       "      <td>0.009338</td>\n",
       "      <td>0.975245</td>\n",
       "      <td>0.011404</td>\n",
       "      <td>0.683131</td>\n",
       "      <td>0.750451</td>\n",
       "      <td>0.676423</td>\n",
       "      <td>0.923661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251134</td>\n",
       "      <td>0.212705</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.977360</td>\n",
       "      <td>0.518564</td>\n",
       "      <td>0.720124</td>\n",
       "      <td>0.305401</td>\n",
       "      <td>0.675188</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.973834</td>\n",
       "      <td>0.795573</td>\n",
       "      <td>0.182144</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.287978</td>\n",
       "      <td>0.864915</td>\n",
       "      <td>0.002588</td>\n",
       "      <td>0.473792</td>\n",
       "      <td>0.455723</td>\n",
       "      <td>0.592317</td>\n",
       "      <td>0.652479</td>\n",
       "      <td>0.901628</td>\n",
       "      <td>0.958366</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.564399</td>\n",
       "      <td>0.467446</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.466350</td>\n",
       "      <td>0.766823</td>\n",
       "      <td>0.356340</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.528631</td>\n",
       "      <td>0.425397</td>\n",
       "      <td>0.144474</td>\n",
       "      <td>0.797371</td>\n",
       "      <td>0.206964</td>\n",
       "      <td>0.944103</td>\n",
       "      <td>0.154332</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.652351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.115304</td>\n",
       "      <td>0.132704</td>\n",
       "      <td>0.058829</td>\n",
       "      <td>0.052093</td>\n",
       "      <td>0.030391</td>\n",
       "      <td>0.044588</td>\n",
       "      <td>0.226563</td>\n",
       "      <td>0.021577</td>\n",
       "      <td>0.029912</td>\n",
       "      <td>0.039258</td>\n",
       "      <td>0.226687</td>\n",
       "      <td>0.056501</td>\n",
       "      <td>0.100600</td>\n",
       "      <td>0.160682</td>\n",
       "      <td>0.221530</td>\n",
       "      <td>0.157684</td>\n",
       "      <td>0.060787</td>\n",
       "      <td>0.054259</td>\n",
       "      <td>0.021069</td>\n",
       "      <td>0.155891</td>\n",
       "      <td>0.427320</td>\n",
       "      <td>0.017356</td>\n",
       "      <td>0.047988</td>\n",
       "      <td>0.065651</td>\n",
       "      <td>0.029063</td>\n",
       "      <td>0.582467</td>\n",
       "      <td>0.049546</td>\n",
       "      <td>0.094049</td>\n",
       "      <td>0.084518</td>\n",
       "      <td>0.132829</td>\n",
       "      <td>0.130267</td>\n",
       "      <td>0.195862</td>\n",
       "      <td>0.059304</td>\n",
       "      <td>0.508515</td>\n",
       "      <td>0.058997</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>0.339720</td>\n",
       "      <td>0.719692</td>\n",
       "      <td>0.050266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>0.506619</td>\n",
       "      <td>0.021308</td>\n",
       "      <td>0.137966</td>\n",
       "      <td>0.743919</td>\n",
       "      <td>0.042207</td>\n",
       "      <td>0.044071</td>\n",
       "      <td>0.277817</td>\n",
       "      <td>0.016746</td>\n",
       "      <td>0.241894</td>\n",
       "      <td>0.246933</td>\n",
       "      <td>0.032122</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>0.078324</td>\n",
       "      <td>0.174977</td>\n",
       "      <td>0.067701</td>\n",
       "      <td>0.033444</td>\n",
       "      <td>0.211241</td>\n",
       "      <td>0.237725</td>\n",
       "      <td>0.164458</td>\n",
       "      <td>0.268323</td>\n",
       "      <td>0.569535</td>\n",
       "      <td>0.089587</td>\n",
       "      <td>0.011176</td>\n",
       "      <td>0.088941</td>\n",
       "      <td>0.323738</td>\n",
       "      <td>0.147319</td>\n",
       "      <td>0.127470</td>\n",
       "      <td>0.206096</td>\n",
       "      <td>0.128958</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.004592</td>\n",
       "      <td>0.349932</td>\n",
       "      <td>0.497275</td>\n",
       "      <td>0.017509</td>\n",
       "      <td>0.036994</td>\n",
       "      <td>0.706145</td>\n",
       "      <td>0.018159</td>\n",
       "      <td>0.004911</td>\n",
       "      <td>0.016304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.006831</td>\n",
       "      <td>0.839499</td>\n",
       "      <td>0.011691</td>\n",
       "      <td>0.676310</td>\n",
       "      <td>0.892242</td>\n",
       "      <td>0.012116</td>\n",
       "      <td>0.578721</td>\n",
       "      <td>0.642392</td>\n",
       "      <td>0.005610</td>\n",
       "      <td>0.021896</td>\n",
       "      <td>0.866786</td>\n",
       "      <td>0.004417</td>\n",
       "      <td>0.831264</td>\n",
       "      <td>0.016619</td>\n",
       "      <td>0.837934</td>\n",
       "      <td>0.542390</td>\n",
       "      <td>0.813424</td>\n",
       "      <td>0.416669</td>\n",
       "      <td>0.648489</td>\n",
       "      <td>0.029095</td>\n",
       "      <td>0.876559</td>\n",
       "      <td>0.016252</td>\n",
       "      <td>0.005036</td>\n",
       "      <td>0.491099</td>\n",
       "      <td>0.057817</td>\n",
       "      <td>0.886672</td>\n",
       "      <td>0.788893</td>\n",
       "      <td>0.816339</td>\n",
       "      <td>0.887080</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>0.828281</td>\n",
       "      <td>0.723763</td>\n",
       "      <td>0.055295</td>\n",
       "      <td>0.958809</td>\n",
       "      <td>0.018945</td>\n",
       "      <td>0.647679</td>\n",
       "      <td>0.945159</td>\n",
       "      <td>0.504467</td>\n",
       "      <td>0.876758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.874309</td>\n",
       "      <td>0.928691</td>\n",
       "      <td>0.009421</td>\n",
       "      <td>0.881100</td>\n",
       "      <td>0.763493</td>\n",
       "      <td>0.620783</td>\n",
       "      <td>0.757361</td>\n",
       "      <td>0.854440</td>\n",
       "      <td>0.005215</td>\n",
       "      <td>0.812121</td>\n",
       "      <td>0.850381</td>\n",
       "      <td>0.930143</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>0.943876</td>\n",
       "      <td>0.847716</td>\n",
       "      <td>0.010996</td>\n",
       "      <td>0.605328</td>\n",
       "      <td>0.811276</td>\n",
       "      <td>0.790742</td>\n",
       "      <td>0.908339</td>\n",
       "      <td>0.849347</td>\n",
       "      <td>0.839488</td>\n",
       "      <td>0.005324</td>\n",
       "      <td>0.001685</td>\n",
       "      <td>0.840654</td>\n",
       "      <td>0.754639</td>\n",
       "      <td>0.008007</td>\n",
       "      <td>0.878216</td>\n",
       "      <td>0.712741</td>\n",
       "      <td>0.637815</td>\n",
       "      <td>0.009659</td>\n",
       "      <td>0.207069</td>\n",
       "      <td>0.674223</td>\n",
       "      <td>0.515196</td>\n",
       "      <td>0.893495</td>\n",
       "      <td>0.444446</td>\n",
       "      <td>0.955914</td>\n",
       "      <td>0.953855</td>\n",
       "      <td>0.007934</td>\n",
       "      <td>0.250554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.885917</td>\n",
       "      <td>0.096429</td>\n",
       "      <td>0.773589</td>\n",
       "      <td>0.650507</td>\n",
       "      <td>0.022017</td>\n",
       "      <td>0.903419</td>\n",
       "      <td>0.833384</td>\n",
       "      <td>0.004758</td>\n",
       "      <td>0.012168</td>\n",
       "      <td>0.756652</td>\n",
       "      <td>0.002675</td>\n",
       "      <td>0.720170</td>\n",
       "      <td>0.013975</td>\n",
       "      <td>0.670773</td>\n",
       "      <td>0.780261</td>\n",
       "      <td>0.229740</td>\n",
       "      <td>0.898469</td>\n",
       "      <td>0.576911</td>\n",
       "      <td>0.006888</td>\n",
       "      <td>0.068969</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.730955</td>\n",
       "      <td>0.008274</td>\n",
       "      <td>0.180409</td>\n",
       "      <td>0.422230</td>\n",
       "      <td>0.783457</td>\n",
       "      <td>0.337070</td>\n",
       "      <td>0.006441</td>\n",
       "      <td>0.836150</td>\n",
       "      <td>0.117267</td>\n",
       "      <td>0.017697</td>\n",
       "      <td>0.898733</td>\n",
       "      <td>0.007879</td>\n",
       "      <td>0.906324</td>\n",
       "      <td>0.164360</td>\n",
       "      <td>0.280883</td>\n",
       "      <td>0.569925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384491</td>\n",
       "      <td>0.143103</td>\n",
       "      <td>0.003422</td>\n",
       "      <td>0.773395</td>\n",
       "      <td>0.897884</td>\n",
       "      <td>0.462670</td>\n",
       "      <td>0.615819</td>\n",
       "      <td>0.163696</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>0.915301</td>\n",
       "      <td>0.686311</td>\n",
       "      <td>0.498028</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.722349</td>\n",
       "      <td>0.958903</td>\n",
       "      <td>0.010239</td>\n",
       "      <td>0.187053</td>\n",
       "      <td>0.452648</td>\n",
       "      <td>0.264134</td>\n",
       "      <td>0.431660</td>\n",
       "      <td>0.887274</td>\n",
       "      <td>0.681674</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.957469</td>\n",
       "      <td>0.738253</td>\n",
       "      <td>0.013733</td>\n",
       "      <td>0.845504</td>\n",
       "      <td>0.734865</td>\n",
       "      <td>0.083917</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.030306</td>\n",
       "      <td>0.327885</td>\n",
       "      <td>0.101516</td>\n",
       "      <td>0.465974</td>\n",
       "      <td>0.160300</td>\n",
       "      <td>0.965753</td>\n",
       "      <td>0.339846</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.016839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         0         1    ...           97        98        99\n",
       "0   0  0.004667  0.073420    ...     0.027851  0.007006  0.022598\n",
       "1   1  0.000423  0.897088    ...     0.154332  0.000864  0.652351\n",
       "2   2  0.115304  0.132704    ...     0.018159  0.004911  0.016304\n",
       "3   3  0.006831  0.839499    ...     0.953855  0.007934  0.250554\n",
       "4   4  0.002555  0.885917    ...     0.339846  0.000933  0.016839\n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"train_16_multi_merge_dropout.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JfiWXVciVt-b"
   },
   "outputs": [],
   "source": [
    "test_16.to_csv(\"test_100_multi_merge_dropout_word2vec.csv\",index=False)\n",
    "test_1.to_csv(\"test_1_multi_merge_dropout_word2vec.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "nz3zsF_Wjlzu",
    "outputId": "d0404aa3-38a3-4292-c61e-134c04fb83b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.654116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.020497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.078235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.001608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.007873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         0\n",
       "0   0  0.654116\n",
       "1   1  0.020497\n",
       "2   2  0.078235\n",
       "3   3  0.001608\n",
       "4   4  0.007873"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"train_1.csv\").head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Multiple Concat + wrod2vec + Dropout.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
